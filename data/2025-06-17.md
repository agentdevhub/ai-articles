<div id='toc'></div>

# 论文分类目录

- **[cs.AI](#csAI)** (4篇)
- **[cs.CL](#csCL)** (2篇)
- **[cs.CE](#csCE)** (1篇)
- **[cs.LG](#csLG)** (2篇)
- **[cs.MA](#csMA)** (2篇)
- **[cs.RO](#csRO)** (1篇)
- **[cs.SE](#csSE)** (1篇)
- **[eess.SY](#eessSY)** (1篇)

---

## cs.AI <a id='csAI'></a>

*本分类共有 4 篇论文*


### [4] [迈向普适分布式智能体生成式人工智能——前沿技术综述](http://arxiv.org/abs/2506.13324v1)
*Gianni Molinari, Fabio Ciravegna*

Main category: cs.AI

TL;DR: 概述智能代理和大型语言模型（LLMs）在普适计算领域的应用及其挑战

<details>
  <summary>Details</summary>
Motivation: 智能代理和大型语言模型的快速发展正在重塑普适计算领域，它们通过自然语言理解感知、推理和行动的能力，在复杂的普适环境中实现自主问题解决

Method: 调查LLM代理的架构组件（分析、记忆、规划和行动），并考察它们在不同场景中的部署和评估，回顾普适计算中的计算和基础设施进步（从云到边缘），以及AI在这一领域的进展

Result: 突出了最先进的代理部署策略和应用，包括在资源受限设备上的本地和分布式执行，识别了这些代理在普适计算中的关键挑战，如架构、能源和隐私限制

Conclusion: 提出了一个名为'代理即工具'的概念框架，强调上下文感知、模块化、安全性、效率和有效性，为普适代理AI提供了一个发展方向

Abstract: The rapid advancement of intelligent agents and Large Language Models (LLMs) is reshaping the pervasive computing field. Their ability to perceive, reason, and act through natural language understanding enables autonomous problem-solving in complex pervasive environments, including the management of heterogeneous sensors, devices, and data. This survey outlines the architectural components of LLM agents (profiling, memory, planning, and action) and examines their deployment and evaluation across various scenarios. Than it reviews computational and infrastructural advancements (cloud to edge) in pervasive computing and how AI is moving in this field. It highlights state-of-the-art agent deployment strategies and applications, including local and distributed execution on resource-constrained devices. This survey identifies key challenges of these agents in pervasive computing such as architectural, energetic and privacy limitations. It finally proposes what we called "Agent as a Tool", a conceptual framework for pervasive agentic AI, emphasizing context awareness, modularity, security, efficiency and effectiveness.
</details>


### [7] [稳态耦合促进亲社会行为](http://arxiv.org/abs/2506.12894v1)
*Naoto Yoshida, Kingson Man*

Main category: cs.AI

TL;DR: 研究自主代理之间亲社会行为的涌现，这些代理由稳态自我调节驱动

<details>
  <summary>Details</summary>
Motivation: 受到生命系统的启发，探索在自主代理中亲社会行为的产生机制

Method: 采用多代理强化学习，将每个代理视为一个脆弱的稳态调节器，引入类似共情的机制来共享代理之间的稳态状态

Result: 在三个简单的多代理环境中，亲社会行为仅在稳态耦合下出现，即当伙伴的痛苦可以影响自己的福祉时。此外，共情可以被学习：代理可以“解码”伙伴的外部情感状态以推断其内部稳态状态

Conclusion: 当稳态代理学会“读取”他人的情感并共情时，亲社会行为就会涌现

Abstract: When regarding the suffering of others, we often experience personal distress and feel compelled to help\footnote{Preprint. Under review.}. Inspired by living systems, we investigate the emergence of prosocial behavior among autonomous agents that are motivated by homeostatic self-regulation. We perform multi-agent reinforcement learning, treating each agent as a vulnerable homeostat charged with maintaining its own well-being. We introduce an empathy-like mechanism to share homeostatic states between agents: an agent can either \emph{observe} their partner's internal state ({\bf cognitive empathy}) or the agent's internal state can be \emph{directly coupled} to that of their partner ({\bf affective empathy}). In three simple multi-agent environments, we show that prosocial behavior arises only under homeostatic coupling - when the distress of a partner can affect one's own well-being. Additionally, we show that empathy can be learned: agents can ``decode" their partner's external emotive states to infer the partner's internal homeostatic states. Assuming some level of physiological similarity, agents reference their own emotion-generation functions to invert the mapping from outward display to internal state. Overall, we demonstrate the emergence of prosocial behavior when homeostatic agents learn to ``read" the emotions of others and then to empathize, or feel as they feel.
</details>


### [8] [终身社交智能评估：语言代理在长期社会互动中的表现](http://arxiv.org/abs/2506.12666v1)
*Hitesh Goel, Hao Zhu*

Main category: cs.AI

TL;DR: 评估语言代理在终身社交互动中的社会智能

<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探讨AI系统是否能够像人类一样通过长期社交互动收集信息并有效导航各种社交情境

Method: 提出新基准LIFELONG-SOTOPIA，通过模拟多集互动对语言代理进行全面评估

Result: 发现所有测试的语言模型的目标达成度和可信度在整个互动过程中下降，尽管使用高级记忆方法提高了代理的性能，但最佳代理在需要明确理解互动历史的情境中的目标完成率仍显著低于人类

Conclusion: LIFELONG-SOTOPIA可用于评估语言代理在终身社交互动中的社会智能

Abstract: Humans engage in lifelong social interactions through interacting with different people under different scenarios for different social goals. This requires social intelligence to gather information through a long time span and use it to navigate various social contexts effectively. Whether AI systems are also capable of this is understudied in the existing research. In this paper, we present a novel benchmark, LIFELONG-SOTOPIA, to perform a comprehensive evaluation of language agents by simulating multi-episode interactions. In each episode, the language agents role-play characters to achieve their respective social goals in randomly sampled social tasks. With LIFELONG-SOTOPIA, we find that goal achievement and believability of all of the language models that we test decline through the whole interaction. Although using an advanced memory method improves the agents' performance, the best agents still achieve a significantly lower goal completion rate than humans on scenarios requiring an explicit understanding of interaction history. These findings show that we can use LIFELONG-SOTOPIA to evaluate the social intelligence of language agents over lifelong social interactions.
</details>


### [14] [《协同智能的呼唤：为何人机协作系统应优先于人工智能自主性》](http://arxiv.org/abs/2506.09420v1)
*Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Chunyu Miao, Dongyuan Li, Aiwei Liu, Yue Zhou, Yankai Chen, Weizhi Zhang, Yangning Li, Liancheng Fang, Renhe Jiang, Philip S. Yu*

Main category: cs.AI

TL;DR: 探讨大型语言模型（LLMs）是否应该追求完全自主的AI代理，以及提出LLM-based Human-Agent Systems（LLM-HAS）作为替代方案

<details>
  <summary>Details</summary>
Motivation: 完全自主的AI系统在可靠性、透明度和理解人类实际需求方面仍存在问题

Method: 提出LLM-HAS方法，通过保持人类的参与来提供指导、回答问题和维持控制，使系统更可信和适应性强

Result: 通过医疗、金融和软件开发等领域的例子展示了人-AI团队合作比AI单独工作更能有效处理复杂任务，并讨论了构建这些协作系统的挑战及实用解决方案

Conclusion: AI的进步不应以系统的独立性来衡量，而应以它们与人类合作的能力来衡量；AI最有前途的未来不在于接管人类角色的系统，而在于通过有意义的伙伴关系增强人类能力的系统

Abstract: Recent improvements in large language models (LLMs) have led many researchers to focus on building fully autonomous AI agents. This position paper questions whether this approach is the right path forward, as these autonomous systems still have problems with reliability, transparency, and understanding the actual requirements of human. We suggest a different approach: LLM-based Human-Agent Systems (LLM-HAS), where AI works with humans rather than replacing them. By keeping human involved to provide guidance, answer questions, and maintain control, these systems can be more trustworthy and adaptable. Looking at examples from healthcare, finance, and software development, we show how human-AI teamwork can handle complex tasks better than AI working alone. We also discuss the challenges of building these collaborative systems and offer practical solutions. This paper argues that progress in AI should not be measured by how independent systems become, but by how well they can work with humans. The most promising future for AI is not in systems that take over human roles, but in those that enhance human capabilities through meaningful partnership.
</details>

[返回目录](#toc)

---

## cs.CL <a id='csCL'></a>

*本分类共有 2 篇论文*


### [3] [基于强化学习的假设驱动临床决策语言智能体](http://arxiv.org/abs/2506.13474v1)
*David Bani-Harouni, Chantal Pellegrini, Ege Özsoy, Matthias Keicher, Nassir Navab*

Main category: cs.CL

TL;DR: 建模临床决策过程以支持诊断

<details>
  <summary>Details</summary>
Motivation: 大型语言模型在临床决策支持中的应用存在两种局限：要么假设所有患者信息立即可用，不模拟交互和迭代的调查过程；要么局限于大型预训练模型的'开箱即用'能力，不进行任务特定训练

Method: 提出一个假设驱动的不确定性感知语言代理LA-CDM，通过反复请求和解释相关测试来收敛于诊断，采用结合监督学习和强化学习的混合训练范式，针对临床决策制定的三个关键方面进行训练：准确的假设生成、假设不确定性估计和高效决策制定

Result: 在MIMIC-CDM数据集上评估，该数据集涵盖四种腹部疾病的各种临床测试，显示明确训练临床决策制定有助于提高诊断性能和效率

Conclusion: 假设驱动的不确定性感知语言代理LA-CDM能有效支持临床决策过程，提高诊断的准确性和效率

Abstract: Clinical decision-making is a dynamic, interactive, and cyclic process where doctors have to repeatedly decide on which clinical action to perform and consider newly uncovered information for diagnosis and treatment. Large Language Models (LLMs) have the potential to support clinicians in this process, however, most applications of LLMs in clinical decision support suffer from one of two limitations: Either they assume the unrealistic scenario of immediate availability of all patient information and do not model the interactive and iterative investigation process, or they restrict themselves to the limited "out-of-the-box" capabilities of large pre-trained models without performing task-specific training. In contrast to this, we propose to model clinical decision-making for diagnosis with a hypothesis-driven uncertainty-aware language agent, LA-CDM, that converges towards a diagnosis via repeatedly requesting and interpreting relevant tests. Using a hybrid training paradigm combining supervised and reinforcement learning, we train LA-CDM with three objectives targeting critical aspects of clinical decision-making: accurate hypothesis generation, hypothesis uncertainty estimation, and efficient decision-making. We evaluate our methodology on MIMIC-CDM, a real-world dataset covering four abdominal diseases containing various clinical tests and show the benefit of explicitly training clinical decision-making for increasing diagnostic performance and efficiency.
</details>


### [10] [行为差距：面向复杂任务对话的零样本大语言模型智能体评估](http://arxiv.org/abs/2506.12266v1)
*Avinash Baidya, Kamalika Das, Xiang Gao*

Main category: cs.CL

TL;DR: 量化AI代理与人类专家在任务导向对话系统中的行为差距

<details>
  <summary>Details</summary>
Motivation: 基于大型语言模型(LLM)的代理在零样本场景下面临显著的性能挑战，行为因素对性能差距的影响尚未充分探索

Method: 提出一个全面的评估框架，专注于对话行为、工具使用和知识利用的差异

Result: 行为差距是影响LLM代理性能的关键因素，任务复杂性增加时行为差距扩大（相关性：0.963），减少行为差距可显著提高性能（平均24.3%）

Conclusion: 全面的行为评估和改进的对齐策略对于提升基于LLM的任务导向对话系统处理复杂任务的有效性至关重要

Abstract: Large Language Model (LLM)-based agents have significantly impacted Task-Oriented Dialog Systems (TODS) but continue to face notable performance challenges, especially in zero-shot scenarios. While prior work has noted this performance gap, the behavioral factors driving the performance gap remain under-explored. This study proposes a comprehensive evaluation framework to quantify the behavior gap between AI agents and human experts, focusing on discrepancies in dialog acts, tool usage, and knowledge utilization. Our findings reveal that this behavior gap is a critical factor negatively impacting the performance of LLM agents. Notably, as task complexity increases, the behavior gap widens (correlation: 0.963), leading to a degradation of agent performance on complex task-oriented dialogs. For the most complex task in our study, even the GPT-4o-based agent exhibits low alignment with human behavior, with low F1 scores for dialog acts (0.464), excessive and often misaligned tool usage with a F1 score of 0.139, and ineffective usage of external knowledge. Reducing such behavior gaps leads to significant performance improvement (24.3% on average). This study highlights the importance of comprehensive behavioral evaluations and improved alignment strategies to enhance the effectiveness of LLM-based TODS in handling complex tasks.
</details>

[返回目录](#toc)

---

## cs.CE <a id='csCE'></a>

*本分类共有 1 篇论文*


### [13] [智能设计4.0：迈向智能体AI时代的范式演进](http://arxiv.org/abs/2506.09755v1)
*Shuo Jiang, Min Xie, Frank Youhua Chen, Jian Ma, Jianxi Luo*

Main category: cs.CE

TL;DR: 介绍智能设计4.0（ID 4.0）作为一个由代理性AI系统赋能的新兴范式

<details>
  <summary>Details</summary>
Motivation: 基础模型（FMs），特别是大型语言模型（LLMs）的出现，展示了基于知识的通用推理能力，为工程设计的进一步转型开辟了新路径

Method: 回顾智能设计的历史演变，提出ID 4.0的概念框架，并讨论其通过协调、自主的多代理系统支持工程设计过程端到端自动化的潜力

Result: 提出了ID 4.0的概念框架，并讨论了其在支持工程设计过程端到端自动化方面的潜力

Conclusion: 这些见解为推进智能设计朝着更大的适应性、自主性和有效性方向发展，以应对日益复杂的设计挑战奠定了基础

Abstract: Research and practice in Intelligent Design (ID) have significantly enhanced engineering innovation, efficiency, quality, and productivity over recent decades, fundamentally reshaping how engineering designers think, behave, and interact with design processes. The recent emergence of Foundation Models (FMs), particularly Large Language Models (LLMs), has demonstrated general knowledge-based reasoning capabilities, and open new paths and avenues for further transformation in engineering design. In this context, this paper introduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by agentic AI systems. We review the historical evolution of ID across four distinct stages: rule-based expert systems, task-specific machine learning models, large-scale foundation AI models, and the recent emerging paradigm of multi-agent collaboration. We propose a conceptual framework for ID 4.0 and discuss its potential to support end-to-end automation of engineering design processes through coordinated, autonomous multi-agent-based systems. Furthermore, we discuss future perspectives to enhance and fully realize ID 4.0's potential, including more complex design scenarios, more practical design implementations, novel agent coordination mechanisms, and autonomous design goal-setting with better human value alignment. In sum, these insights lay a foundation for advancing Intelligent Design toward greater adaptivity, autonomy, and effectiveness in addressing increasingly complex design challenges.
</details>

[返回目录](#toc)

---

## cs.LG <a id='csLG'></a>

*本分类共有 2 篇论文*


### [1] [我们应识别并缓解MCP驱动智能体系统中的第三方安全风险](http://arxiv.org/abs/2506.13666v1)
*Junfeng Fang, Zijun Yao, Ruipeng Wang, Haokai Ma, Xiang Wang, Tat-Seng Chua*

Main category: cs.LG

TL;DR: 研究模型上下文协议（MCP）引入的新安全风险及构建安全的MCP驱动代理系统

<details>
  <summary>Details</summary>
Motivation: MCP作为大型语言模型（LLM）代理系统的实际标准，引入了不受LLM开发者控制的第三方服务，这些服务提供商可能恶意利用漏洞破坏用户与代理的交互

Method: 构建一个受控框架来检查MCP驱动代理系统中的安全问题，进行一系列试点实验展示安全风险的真实威胁及其防御的复杂性，并提出构建安全MCP驱动代理系统的路线图

Result: 通过试点实验证实MCP驱动代理系统的安全风险是真实存在的威胁，且其防御并非易事

Conclusion: 呼吁研究社区关注MCP引入的新安全风险，并开发新技术以构建安全的MCP驱动代理系统，提出了包括红队测试、MCP安全LLM开发等研究方向

Abstract: The development of large language models (LLMs) has entered in a experience-driven era, flagged by the emergence of environment feedback-driven learning via reinforcement learning and tool-using agents. This encourages the emergenece of model context protocol (MCP), which defines the standard on how should a LLM interact with external services, such as \api and data. However, as MCP becomes the de facto standard for LLM agent systems, it also introduces new safety risks. In particular, MCP introduces third-party services, which are not controlled by the LLM developers, into the agent systems. These third-party MCP services provider are potentially malicious and have the economic incentives to exploit vulnerabilities and sabotage user-agent interactions. In this position paper, we advocate the research community in LLM safety to pay close attention to the new safety risks issues introduced by MCP, and develop new techniques to build safe MCP-powered agent systems. To establish our position, we argue with three key parts. (1) We first construct \framework, a controlled framework to examine safety issues in MCP-powered agent systems. (2) We then conduct a series of pilot experiments to demonstrate the safety risks in MCP-powered agent systems is a real threat and its defense is not trivial. (3) Finally, we give our outlook by showing a roadmap to build safe MCP-powered agent systems. In particular, we would call for researchers to persue the following research directions: red teaming, MCP safe LLM development, MCP safety evaluation, MCP safety data accumulation, MCP service safeguard, and MCP safe ecosystem construction. We hope this position paper can raise the awareness of the research community in MCP safety and encourage more researchers to join this important research direction. Our code is available at https://github.com/littlelittlenine/SafeMCP.git.
</details>


### [9] [《从神经信号映射到智能体表现：迈向基于神经反馈的强化学习》](http://arxiv.org/abs/2506.12636v1)
*Julia Santaniello, Matthew Russell, Benson Jiang, Donatello Sassaroli, Robert Jacob, Jivko Sinapov*

Main category: cs.LG

TL;DR: 将被动人类反馈整合到自主代理训练中的隐式人机循环强化学习（HITL-RL）方法

<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖主动指令，要求参与者通过不自然的表达或手势来教导代理

Method: 引入NEURO-LOOP框架，利用内在人类奖励系统驱动人机交互，并使用功能性近红外光谱（fNIRS）设计数据集

Result: 证明了fNIRS数据与代理性能之间存在关系，使用经典机器学习技术

Conclusion: 神经接口可能为未来的人机交互、辅助AI和自适应自主系统应用提供潜力

Abstract: Implicit Human-in-the-Loop Reinforcement Learning (HITL-RL) is a methodology that integrates passive human feedback into autonomous agent training while minimizing human workload. However, existing methods often rely on active instruction, requiring participants to teach an agent through unnatural expression or gesture. We introduce NEURO-LOOP, an implicit feedback framework that utilizes the intrinsic human reward system to drive human-agent interaction. This work demonstrates the feasibility of a critical first step in the NEURO-LOOP framework: mapping brain signals to agent performance. Using functional near-infrared spectroscopy (fNIRS), we design a dataset to enable future research using passive Brain-Computer Interfaces for Human-in-the-Loop Reinforcement Learning. Participants are instructed to observe or guide a reinforcement learning agent in its environment while signals from the prefrontal cortex are collected. We conclude that a relationship between fNIRS data and agent performance exists using classical machine learning techniques. Finally, we highlight the potential that neural interfaces may offer to future applications of human-agent interaction, assistive AI, and adaptive autonomous systems.
</details>

[返回目录](#toc)

---

## cs.MA <a id='csMA'></a>

*本分类共有 2 篇论文*


### [6] [迈向城市物流自主优化：基于智能数字孪生与模型上下文协议的科学工具训练生成式人工智能](http://arxiv.org/abs/2506.13068v1)
*Haowen Xu, Yulin Sun, Jose Tupayachi, Olufemi Omitaomu, Sisi Zlatanov, Xueping Li*

Main category: cs.MA

TL;DR: 优化城市货运物流以发展可持续、低碳城市

<details>
  <summary>Details</summary>
Motivation: 传统方法依赖人工协调模拟工具、优化求解器和专家驱动的工作流程，限制了效率和可扩展性

Method: 提出一种代理系统架构，利用模型上下文协议（MCP）协调科学工具之间的多代理协作，实现城市物流中的自主、模拟知情优化

Result: 通过货运脱碳案例研究展示了MCP如何在不同工具链中实现模块化、互操作和适应性代理行为，将数字孪生从静态可视化转变为自主、有决策能力的系统

Conclusion: 通过使上下文感知、生成代理能够自动和协作地操作科学工具，该框架支持更智能、可访问和动态的交通规划和智能城市管理决策

Abstract: Optimizing urban freight logistics is critical for developing sustainable, low-carbon cities. Traditional methods often rely on manual coordination of simulation tools, optimization solvers, and expert-driven workflows, limiting their efficiency and scalability. This paper presents an agentic system architecture that leverages the model context protocol (MCP) to orchestrate multi-agent collaboration among scientific tools for autonomous, simulation-informed optimization in urban logistics. The system integrates generative AI agents with domain-specific engines - such as Gurobi for optimization and AnyLogic for agent-based simulation - forming a generative digital twin capable of reasoning, planning, and acting across multimodal freight networks. By incorporating integrated chatbots, retrieval-augmented generation, and structured memory, the framework enables agents to interpret user intent from natural language conversations, retrieve relevant datasets and models, coordinate solvers and simulators, and execute complex workflows. We demonstrate this approach through a freight decarbonization case study, showcasing how MCP enables modular, interoperable, and adaptive agent behavior across diverse toolchains. The results reveal that our system transforms digital twins from static visualizations into autonomous, decision-capable systems, advancing the frontiers of urban operations research. By enabling context-aware, generative agents to operate scientific tools automatically and collaboratively, this framework supports more intelligent, accessible, and dynamic decision-making in transportation planning and smart city management.
</details>


### [12] [基于AutoGen驱动的多智能体框架在犯罪数据迭代分析与预测中的应用](http://arxiv.org/abs/2506.11475v1)
*Syeda Kisaa Fatima, Tehreem Zubair, Noman Ahmed, Asifullah Khan*

Main category: cs.MA

TL;DR: 介绍LUCID-MA框架，一个创新的AI驱动框架，通过多代理对话学习和理解犯罪数据

<details>
  <summary>Details</summary>
Motivation: 为了通过多AI代理协作分析和理解犯罪数据，减少人工干预，同时保持数据隐私

Method: 系统包含三个核心组件：分析助手、反馈组件和预测组件，使用LLaMA-2-13B-Chat-GPTQ模型和精心设计的提示，完全离线运行，并通过100轮通信实现自我改进

Result: 通过评分函数评估代理性能，提供视觉图跟踪学习进度，展示了AutoGen风格代理在社会科学领域进行自主、可扩展和迭代分析的潜力

Conclusion: LUCID-MA框架展示了通过离线执行保持数据隐私的同时，利用多AI代理协作进行犯罪数据分析和预测的潜力

Abstract: This paper introduces LUCID-MA (Learning and Understanding Crime through Dialogue of Multiple Agents), an innovative AI powered framework where multiple AI agents collaboratively analyze and understand crime data. Our system that consists of three core components: an analysis assistant that highlights spatiotemporal crime patterns, a feedback component that reviews and refines analytical results and a prediction component that forecasts future crime trends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it runs completely offline and allows the agents undergo self-improvement through 100 rounds of communication with less human interaction. A scoring function is incorporated to evaluate agent's performance, providing visual plots to track learning progress. This work demonstrates the potential of AutoGen-style agents for autonomous, scalable, and iterative analysis in social science domains maintaining data privacy through offline execution.
</details>

[返回目录](#toc)

---

## cs.RO <a id='csRO'></a>

*本分类共有 1 篇论文*


### [11] [机器人上下文协议（RCP）：一种运行时无关的智能体感知机器人控制接口](http://arxiv.org/abs/2506.11650v1)
*Lambert Lee, Joshua Lau*

Main category: cs.RO

TL;DR: 设计Robot Context Protocol（RCP）以简化机器人系统的复杂性并实现机器人、用户和自主代理之间的无缝交互

<details>
  <summary>Details</summary>
Motivation: 为了支持包括物理机器人、基于云的协调器和模拟平台在内的广泛部署环境，需要一个统一且语义上有意义的接口来解耦面向客户的操作与后端实现

Method: 基于HTTP和WebSocket传输层，定义了一个模式驱动的消息格式，包括读取、写入、执行和订阅等结构化操作，并集成了运行时自省、异步反馈、多租户命名空间隔离和严格的类型验证等功能

Result: 描述了RCP的架构、消息结构、接口模型和基于适配器的后端集成策略，以及部署实践和在制造业、物流和医疗保健等行业的适用性

Conclusion: RCP能够在复杂的多代理生态系统中实现智能、弹性和安全的机器人操作

Abstract: The Robot Context Protocol (RCP) is a lightweight, middleware-agnostic communication protocol designed to simplify the complexity of robotic systems and enable seamless interaction between robots, users, and autonomous agents. RCP provides a unified and semantically meaningful interface that decouples client-facing operations from backend implementations, supporting a wide range of deployment environments including physical robots, cloud-based orchestrators, and simulated platforms. Built on HTTP and WebSocket transport layers, the protocol defines a schema-driven message format with structured operations such as read, write, execute, and subscribe. It integrates features such as runtime introspection, asynchronous feedback, multi-tenant namespace isolation, and strict type validation to ensure robustness, scalability, and security. The architecture, message structure, interface model, and adapter-based backend integration strategy of RCP are described, along with deployment practices and applicability across industries including manufacturing, logistics, and healthcare. RCP enables intelligent, resilient, and safe robotic operations in complex, multi-agent ecosystems.
</details>

[返回目录](#toc)

---

## cs.SE <a id='csSE'></a>

*本分类共有 1 篇论文*


### [5] [查询大型汽车软件模型：智能代理与直接LLM方法对比](http://arxiv.org/abs/2506.13171v1)
*Lukasz Mazur, Nenad Petrovic, James Pontes Miranda, Ansgar Radermacher, Robert Rasche, Alois Knoll*

Main category: cs.SE

TL;DR: 利用大型语言模型（LLMs）回答关于软件模型的问题

<details>
  <summary>Details</summary>
Motivation: 大型软件模型难以整体把握，传统交互和分析方法面临挑战

Method: 研究两种方法：直接提示法和基于LLM的代理与通用文件访问工具结合的代理方法

Result: 代理方法在准确性上与直接提示法相当，但在令牌使用上显著更高效

Conclusion: 代理方法特别适合汽车行业，对于大型软件模型，LLM代理不仅是实用的替代方案，而且是唯一可行的解决方案

Abstract: Large language models (LLMs) offer new opportunities for interacting with complex software artifacts, such as software models, through natural language. They present especially promising benefits for large software models that are difficult to grasp in their entirety, making traditional interaction and analysis approaches challenging. This paper investigates two approaches for leveraging LLMs to answer questions over software models: direct prompting, where the whole software model is provided in the context, and an agentic approach combining LLM-based agents with general-purpose file access tools. We evaluate these approaches using an Ecore metamodel designed for timing analysis and software optimization in automotive and embedded domains. Our findings show that while the agentic approach achieves accuracy comparable to direct prompting, it is significantly more efficient in terms of token usage. This efficiency makes the agentic approach particularly suitable for the automotive industry, where the large size of software models makes direct prompting infeasible, establishing LLM agents as not just a practical alternative but the only viable solution. Notably, the evaluation was conducted using small LLMs, which are more feasible to be executed locally - an essential advantage for meeting strict requirements around privacy, intellectual property protection, and regulatory compliance. Future work will investigate software models in diverse formats, explore more complex agent architectures, and extend agentic workflows to support not only querying but also modification of software models.
</details>

[返回目录](#toc)

---

## eess.SY <a id='eessSY'></a>

*本分类共有 1 篇论文*


### [2] [欺骗性路径规划：一种贝叶斯博弈方法](http://arxiv.org/abs/2506.13650v1)
*Violetta Rostobaya, James Berneburg, Yue Guan, Michael Dorothy, Daigo Shishika*

Main category: eess.SY

TL;DR: 研究自主代理在对抗性环境中如何通过其运动传递信息

<details>
  <summary>Details</summary>
Motivation: 考虑代理在必须达到其目标的同时，还需要欺骗智能观察者关于其目的地的情况

Method: 将这种互动建模为具有私有已知目标的移动攻击者与推断攻击者意图以有效分配防御资源的防御者之间的动态贝叶斯博弈，并使用完美贝叶斯纳什均衡（PBNE）作为解决方案概念，提出一种计算高效的方法来找到它

Result: 数值实验表明，基于PBNE的策略在操纵防御者信念方面，通过随机混合最短和非最短路径来战略性地平衡欺骗和目标效率，优于基于单边优化的现有方法

Conclusion: 在对抗性环境中，自主代理可以通过战略性地平衡欺骗和目标效率来有效地传递信息

Abstract: This paper investigates how an autonomous agent can transmit information through its motion in an adversarial setting. We consider scenarios where an agent must reach its goal while deceiving an intelligent observer about its destination. We model this interaction as a dynamic Bayesian game between a mobile Attacker with a privately known goal and a Defender who infers the Attacker's intent to allocate defensive resources effectively. We use Perfect Bayesian Nash Equilibrium (PBNE) as our solution concept and propose a computationally efficient approach to find it. In the resulting equilibrium, the Defender employs a simple Markovian strategy, while the Attacker strategically balances deception and goal efficiency by stochastically mixing shortest and non-shortest paths to manipulate the Defender's beliefs. Numerical experiments demonstrate the advantages of our PBNE-based strategies over existing methods based on one-sided optimization.
</details>

[返回目录](#toc)

---

