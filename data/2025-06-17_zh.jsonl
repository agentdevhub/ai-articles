{"id": "2506.13666v1", "pdf": "http://arxiv.org/pdf/2506.13666v1", "abs": "http://arxiv.org/abs/2506.13666v1", "authors": ["Junfeng Fang", "Zijun Yao", "Ruipeng Wang", "Haokai Ma", "Xiang Wang", "Tat-Seng Chua"], "title": "We Should Identify and Mitigate Third-Party Safety Risks in MCP-Powered Agent Systems", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The development of large language models (LLMs) has entered in a\nexperience-driven era, flagged by the emergence of environment feedback-driven\nlearning via reinforcement learning and tool-using agents. This encourages the\nemergenece of model context protocol (MCP), which defines the standard on how\nshould a LLM interact with external services, such as \\api and data. However,\nas MCP becomes the de facto standard for LLM agent systems, it also introduces\nnew safety risks. In particular, MCP introduces third-party services, which are\nnot controlled by the LLM developers, into the agent systems. These third-party\nMCP services provider are potentially malicious and have the economic\nincentives to exploit vulnerabilities and sabotage user-agent interactions. In\nthis position paper, we advocate the research community in LLM safety to pay\nclose attention to the new safety risks issues introduced by MCP, and develop\nnew techniques to build safe MCP-powered agent systems. To establish our\nposition, we argue with three key parts. (1) We first construct \\framework, a\ncontrolled framework to examine safety issues in MCP-powered agent systems. (2)\nWe then conduct a series of pilot experiments to demonstrate the safety risks\nin MCP-powered agent systems is a real threat and its defense is not trivial.\n(3) Finally, we give our outlook by showing a roadmap to build safe MCP-powered\nagent systems. In particular, we would call for researchers to persue the\nfollowing research directions: red teaming, MCP safe LLM development, MCP\nsafety evaluation, MCP safety data accumulation, MCP service safeguard, and MCP\nsafe ecosystem construction. We hope this position paper can raise the\nawareness of the research community in MCP safety and encourage more\nresearchers to join this important research direction. Our code is available at\nhttps://github.com/littlelittlenine/SafeMCP.git.", "title_zh": "我们应识别并缓解MCP驱动智能体系统中的第三方安全风险", "AI": {"task": "研究模型上下文协议（MCP）引入的新安全风险及构建安全的MCP驱动代理系统", "motivation": "MCP作为大型语言模型（LLM）代理系统的实际标准，引入了不受LLM开发者控制的第三方服务，这些服务提供商可能恶意利用漏洞破坏用户与代理的交互", "method": "构建一个受控框架来检查MCP驱动代理系统中的安全问题，进行一系列试点实验展示安全风险的真实威胁及其防御的复杂性，并提出构建安全MCP驱动代理系统的路线图", "result": "通过试点实验证实MCP驱动代理系统的安全风险是真实存在的威胁，且其防御并非易事", "conclusion": "呼吁研究社区关注MCP引入的新安全风险，并开发新技术以构建安全的MCP驱动代理系统，提出了包括红队测试、MCP安全LLM开发等研究方向"}}
{"id": "2506.13650v1", "pdf": "http://arxiv.org/pdf/2506.13650v1", "abs": "http://arxiv.org/abs/2506.13650v1", "authors": ["Violetta Rostobaya", "James Berneburg", "Yue Guan", "Michael Dorothy", "Daigo Shishika"], "title": "Deceptive Path Planning: A Bayesian Game Approach", "categories": ["eess.SY", "cs.GT", "cs.MA", "cs.SY"], "comment": "8 pages, 9 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "This paper investigates how an autonomous agent can transmit information\nthrough its motion in an adversarial setting. We consider scenarios where an\nagent must reach its goal while deceiving an intelligent observer about its\ndestination. We model this interaction as a dynamic Bayesian game between a\nmobile Attacker with a privately known goal and a Defender who infers the\nAttacker's intent to allocate defensive resources effectively. We use Perfect\nBayesian Nash Equilibrium (PBNE) as our solution concept and propose a\ncomputationally efficient approach to find it. In the resulting equilibrium,\nthe Defender employs a simple Markovian strategy, while the Attacker\nstrategically balances deception and goal efficiency by stochastically mixing\nshortest and non-shortest paths to manipulate the Defender's beliefs. Numerical\nexperiments demonstrate the advantages of our PBNE-based strategies over\nexisting methods based on one-sided optimization.", "title_zh": "欺骗性路径规划：一种贝叶斯博弈方法", "AI": {"task": "研究自主代理在对抗性环境中如何通过其运动传递信息", "motivation": "考虑代理在必须达到其目标的同时，还需要欺骗智能观察者关于其目的地的情况", "method": "将这种互动建模为具有私有已知目标的移动攻击者与推断攻击者意图以有效分配防御资源的防御者之间的动态贝叶斯博弈，并使用完美贝叶斯纳什均衡（PBNE）作为解决方案概念，提出一种计算高效的方法来找到它", "result": "数值实验表明，基于PBNE的策略在操纵防御者信念方面，通过随机混合最短和非最短路径来战略性地平衡欺骗和目标效率，优于基于单边优化的现有方法", "conclusion": "在对抗性环境中，自主代理可以通过战略性地平衡欺骗和目标效率来有效地传递信息"}}
{"id": "2506.13474v1", "pdf": "http://arxiv.org/pdf/2506.13474v1", "abs": "http://arxiv.org/abs/2506.13474v1", "authors": ["David Bani-Harouni", "Chantal Pellegrini", "Ege Özsoy", "Matthias Keicher", "Nassir Navab"], "title": "Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Clinical decision-making is a dynamic, interactive, and cyclic process where\ndoctors have to repeatedly decide on which clinical action to perform and\nconsider newly uncovered information for diagnosis and treatment. Large\nLanguage Models (LLMs) have the potential to support clinicians in this\nprocess, however, most applications of LLMs in clinical decision support suffer\nfrom one of two limitations: Either they assume the unrealistic scenario of\nimmediate availability of all patient information and do not model the\ninteractive and iterative investigation process, or they restrict themselves to\nthe limited \"out-of-the-box\" capabilities of large pre-trained models without\nperforming task-specific training. In contrast to this, we propose to model\nclinical decision-making for diagnosis with a hypothesis-driven\nuncertainty-aware language agent, LA-CDM, that converges towards a diagnosis\nvia repeatedly requesting and interpreting relevant tests. Using a hybrid\ntraining paradigm combining supervised and reinforcement learning, we train\nLA-CDM with three objectives targeting critical aspects of clinical\ndecision-making: accurate hypothesis generation, hypothesis uncertainty\nestimation, and efficient decision-making. We evaluate our methodology on\nMIMIC-CDM, a real-world dataset covering four abdominal diseases containing\nvarious clinical tests and show the benefit of explicitly training clinical\ndecision-making for increasing diagnostic performance and efficiency.", "title_zh": "基于强化学习的假设驱动临床决策语言智能体", "AI": {"task": "建模临床决策过程以支持诊断", "motivation": "大型语言模型在临床决策支持中的应用存在两种局限：要么假设所有患者信息立即可用，不模拟交互和迭代的调查过程；要么局限于大型预训练模型的'开箱即用'能力，不进行任务特定训练", "method": "提出一个假设驱动的不确定性感知语言代理LA-CDM，通过反复请求和解释相关测试来收敛于诊断，采用结合监督学习和强化学习的混合训练范式，针对临床决策制定的三个关键方面进行训练：准确的假设生成、假设不确定性估计和高效决策制定", "result": "在MIMIC-CDM数据集上评估，该数据集涵盖四种腹部疾病的各种临床测试，显示明确训练临床决策制定有助于提高诊断性能和效率", "conclusion": "假设驱动的不确定性感知语言代理LA-CDM能有效支持临床决策过程，提高诊断的准确性和效率"}}
{"id": "2506.13324v1", "pdf": "http://arxiv.org/pdf/2506.13324v1", "abs": "http://arxiv.org/abs/2506.13324v1", "authors": ["Gianni Molinari", "Fabio Ciravegna"], "title": "Towards Pervasive Distributed Agentic Generative AI -- A State of The Art", "categories": ["cs.AI", "cs.MA"], "comment": null, "summary": "The rapid advancement of intelligent agents and Large Language Models (LLMs)\nis reshaping the pervasive computing field. Their ability to perceive, reason,\nand act through natural language understanding enables autonomous\nproblem-solving in complex pervasive environments, including the management of\nheterogeneous sensors, devices, and data. This survey outlines the\narchitectural components of LLM agents (profiling, memory, planning, and\naction) and examines their deployment and evaluation across various scenarios.\nThan it reviews computational and infrastructural advancements (cloud to edge)\nin pervasive computing and how AI is moving in this field. It highlights\nstate-of-the-art agent deployment strategies and applications, including local\nand distributed execution on resource-constrained devices. This survey\nidentifies key challenges of these agents in pervasive computing such as\narchitectural, energetic and privacy limitations. It finally proposes what we\ncalled \"Agent as a Tool\", a conceptual framework for pervasive agentic AI,\nemphasizing context awareness, modularity, security, efficiency and\neffectiveness.", "title_zh": "迈向普适分布式智能体生成式人工智能——前沿技术综述", "AI": {"task": "概述智能代理和大型语言模型（LLMs）在普适计算领域的应用及其挑战", "motivation": "智能代理和大型语言模型的快速发展正在重塑普适计算领域，它们通过自然语言理解感知、推理和行动的能力，在复杂的普适环境中实现自主问题解决", "method": "调查LLM代理的架构组件（分析、记忆、规划和行动），并考察它们在不同场景中的部署和评估，回顾普适计算中的计算和基础设施进步（从云到边缘），以及AI在这一领域的进展", "result": "突出了最先进的代理部署策略和应用，包括在资源受限设备上的本地和分布式执行，识别了这些代理在普适计算中的关键挑战，如架构、能源和隐私限制", "conclusion": "提出了一个名为'代理即工具'的概念框架，强调上下文感知、模块化、安全性、效率和有效性，为普适代理AI提供了一个发展方向"}}
{"id": "2506.13171v1", "pdf": "http://arxiv.org/pdf/2506.13171v1", "abs": "http://arxiv.org/abs/2506.13171v1", "authors": ["Lukasz Mazur", "Nenad Petrovic", "James Pontes Miranda", "Ansgar Radermacher", "Robert Rasche", "Alois Knoll"], "title": "Querying Large Automotive Software Models: Agentic vs. Direct LLM Approaches", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) offer new opportunities for interacting with\ncomplex software artifacts, such as software models, through natural language.\nThey present especially promising benefits for large software models that are\ndifficult to grasp in their entirety, making traditional interaction and\nanalysis approaches challenging. This paper investigates two approaches for\nleveraging LLMs to answer questions over software models: direct prompting,\nwhere the whole software model is provided in the context, and an agentic\napproach combining LLM-based agents with general-purpose file access tools. We\nevaluate these approaches using an Ecore metamodel designed for timing analysis\nand software optimization in automotive and embedded domains. Our findings show\nthat while the agentic approach achieves accuracy comparable to direct\nprompting, it is significantly more efficient in terms of token usage. This\nefficiency makes the agentic approach particularly suitable for the automotive\nindustry, where the large size of software models makes direct prompting\ninfeasible, establishing LLM agents as not just a practical alternative but the\nonly viable solution. Notably, the evaluation was conducted using small LLMs,\nwhich are more feasible to be executed locally - an essential advantage for\nmeeting strict requirements around privacy, intellectual property protection,\nand regulatory compliance. Future work will investigate software models in\ndiverse formats, explore more complex agent architectures, and extend agentic\nworkflows to support not only querying but also modification of software\nmodels.", "title_zh": "查询大型汽车软件模型：智能代理与直接LLM方法对比", "AI": {"task": "利用大型语言模型（LLMs）回答关于软件模型的问题", "motivation": "大型软件模型难以整体把握，传统交互和分析方法面临挑战", "method": "研究两种方法：直接提示法和基于LLM的代理与通用文件访问工具结合的代理方法", "result": "代理方法在准确性上与直接提示法相当，但在令牌使用上显著更高效", "conclusion": "代理方法特别适合汽车行业，对于大型软件模型，LLM代理不仅是实用的替代方案，而且是唯一可行的解决方案"}}
{"id": "2506.13068v1", "pdf": "http://arxiv.org/pdf/2506.13068v1", "abs": "http://arxiv.org/abs/2506.13068v1", "authors": ["Haowen Xu", "Yulin Sun", "Jose Tupayachi", "Olufemi Omitaomu", "Sisi Zlatanov", "Xueping Li"], "title": "Towards the Autonomous Optimization of Urban Logistics: Training Generative AI with Scientific Tools via Agentic Digital Twins and Model Context Protocol", "categories": ["cs.MA"], "comment": null, "summary": "Optimizing urban freight logistics is critical for developing sustainable,\nlow-carbon cities. Traditional methods often rely on manual coordination of\nsimulation tools, optimization solvers, and expert-driven workflows, limiting\ntheir efficiency and scalability. This paper presents an agentic system\narchitecture that leverages the model context protocol (MCP) to orchestrate\nmulti-agent collaboration among scientific tools for autonomous,\nsimulation-informed optimization in urban logistics. The system integrates\ngenerative AI agents with domain-specific engines - such as Gurobi for\noptimization and AnyLogic for agent-based simulation - forming a generative\ndigital twin capable of reasoning, planning, and acting across multimodal\nfreight networks. By incorporating integrated chatbots, retrieval-augmented\ngeneration, and structured memory, the framework enables agents to interpret\nuser intent from natural language conversations, retrieve relevant datasets and\nmodels, coordinate solvers and simulators, and execute complex workflows. We\ndemonstrate this approach through a freight decarbonization case study,\nshowcasing how MCP enables modular, interoperable, and adaptive agent behavior\nacross diverse toolchains. The results reveal that our system transforms\ndigital twins from static visualizations into autonomous, decision-capable\nsystems, advancing the frontiers of urban operations research. By enabling\ncontext-aware, generative agents to operate scientific tools automatically and\ncollaboratively, this framework supports more intelligent, accessible, and\ndynamic decision-making in transportation planning and smart city management.", "title_zh": "迈向城市物流自主优化：基于智能数字孪生与模型上下文协议的科学工具训练生成式人工智能", "AI": {"task": "优化城市货运物流以发展可持续、低碳城市", "motivation": "传统方法依赖人工协调模拟工具、优化求解器和专家驱动的工作流程，限制了效率和可扩展性", "method": "提出一种代理系统架构，利用模型上下文协议（MCP）协调科学工具之间的多代理协作，实现城市物流中的自主、模拟知情优化", "result": "通过货运脱碳案例研究展示了MCP如何在不同工具链中实现模块化、互操作和适应性代理行为，将数字孪生从静态可视化转变为自主、有决策能力的系统", "conclusion": "通过使上下文感知、生成代理能够自动和协作地操作科学工具，该框架支持更智能、可访问和动态的交通规划和智能城市管理决策"}}
{"id": "2506.12894v1", "pdf": "http://arxiv.org/pdf/2506.12894v1", "abs": "http://arxiv.org/abs/2506.12894v1", "authors": ["Naoto Yoshida", "Kingson Man"], "title": "Homeostatic Coupling for Prosocial Behavior", "categories": ["cs.AI", "cs.MA"], "comment": "Preprint. Unver review", "summary": "When regarding the suffering of others, we often experience personal distress\nand feel compelled to help\\footnote{Preprint. Under review.}. Inspired by\nliving systems, we investigate the emergence of prosocial behavior among\nautonomous agents that are motivated by homeostatic self-regulation. We perform\nmulti-agent reinforcement learning, treating each agent as a vulnerable\nhomeostat charged with maintaining its own well-being. We introduce an\nempathy-like mechanism to share homeostatic states between agents: an agent can\neither \\emph{observe} their partner's internal state ({\\bf cognitive empathy})\nor the agent's internal state can be \\emph{directly coupled} to that of their\npartner ({\\bf affective empathy}). In three simple multi-agent environments, we\nshow that prosocial behavior arises only under homeostatic coupling - when the\ndistress of a partner can affect one's own well-being. Additionally, we show\nthat empathy can be learned: agents can ``decode\" their partner's external\nemotive states to infer the partner's internal homeostatic states. Assuming\nsome level of physiological similarity, agents reference their own\nemotion-generation functions to invert the mapping from outward display to\ninternal state. Overall, we demonstrate the emergence of prosocial behavior\nwhen homeostatic agents learn to ``read\" the emotions of others and then to\nempathize, or feel as they feel.", "title_zh": "稳态耦合促进亲社会行为", "AI": {"task": "研究自主代理之间亲社会行为的涌现，这些代理由稳态自我调节驱动", "motivation": "受到生命系统的启发，探索在自主代理中亲社会行为的产生机制", "method": "采用多代理强化学习，将每个代理视为一个脆弱的稳态调节器，引入类似共情的机制来共享代理之间的稳态状态", "result": "在三个简单的多代理环境中，亲社会行为仅在稳态耦合下出现，即当伙伴的痛苦可以影响自己的福祉时。此外，共情可以被学习：代理可以“解码”伙伴的外部情感状态以推断其内部稳态状态", "conclusion": "当稳态代理学会“读取”他人的情感并共情时，亲社会行为就会涌现"}}
{"id": "2506.12666v1", "pdf": "http://arxiv.org/pdf/2506.12666v1", "abs": "http://arxiv.org/abs/2506.12666v1", "authors": ["Hitesh Goel", "Hao Zhu"], "title": "LIFELONG SOTOPIA: Evaluating Social Intelligence of Language Agents Over Lifelong Social Interactions", "categories": ["cs.AI"], "comment": null, "summary": "Humans engage in lifelong social interactions through interacting with\ndifferent people under different scenarios for different social goals. This\nrequires social intelligence to gather information through a long time span and\nuse it to navigate various social contexts effectively. Whether AI systems are\nalso capable of this is understudied in the existing research. In this paper,\nwe present a novel benchmark, LIFELONG-SOTOPIA, to perform a comprehensive\nevaluation of language agents by simulating multi-episode interactions. In each\nepisode, the language agents role-play characters to achieve their respective\nsocial goals in randomly sampled social tasks. With LIFELONG-SOTOPIA, we find\nthat goal achievement and believability of all of the language models that we\ntest decline through the whole interaction. Although using an advanced memory\nmethod improves the agents' performance, the best agents still achieve a\nsignificantly lower goal completion rate than humans on scenarios requiring an\nexplicit understanding of interaction history. These findings show that we can\nuse LIFELONG-SOTOPIA to evaluate the social intelligence of language agents\nover lifelong social interactions.", "title_zh": "终身社交智能评估：语言代理在长期社会互动中的表现", "AI": {"task": "评估语言代理在终身社交互动中的社会智能", "motivation": "现有研究未充分探讨AI系统是否能够像人类一样通过长期社交互动收集信息并有效导航各种社交情境", "method": "提出新基准LIFELONG-SOTOPIA，通过模拟多集互动对语言代理进行全面评估", "result": "发现所有测试的语言模型的目标达成度和可信度在整个互动过程中下降，尽管使用高级记忆方法提高了代理的性能，但最佳代理在需要明确理解互动历史的情境中的目标完成率仍显著低于人类", "conclusion": "LIFELONG-SOTOPIA可用于评估语言代理在终身社交互动中的社会智能"}}
{"id": "2506.12636v1", "pdf": "http://arxiv.org/pdf/2506.12636v1", "abs": "http://arxiv.org/abs/2506.12636v1", "authors": ["Julia Santaniello", "Matthew Russell", "Benson Jiang", "Donatello Sassaroli", "Robert Jacob", "Jivko Sinapov"], "title": "Mapping Neural Signals to Agent Performance, A Step Towards Reinforcement Learning from Neural Feedback", "categories": ["cs.LG"], "comment": null, "summary": "Implicit Human-in-the-Loop Reinforcement Learning (HITL-RL) is a methodology\nthat integrates passive human feedback into autonomous agent training while\nminimizing human workload. However, existing methods often rely on active\ninstruction, requiring participants to teach an agent through unnatural\nexpression or gesture. We introduce NEURO-LOOP, an implicit feedback framework\nthat utilizes the intrinsic human reward system to drive human-agent\ninteraction. This work demonstrates the feasibility of a critical first step in\nthe NEURO-LOOP framework: mapping brain signals to agent performance. Using\nfunctional near-infrared spectroscopy (fNIRS), we design a dataset to enable\nfuture research using passive Brain-Computer Interfaces for Human-in-the-Loop\nReinforcement Learning. Participants are instructed to observe or guide a\nreinforcement learning agent in its environment while signals from the\nprefrontal cortex are collected. We conclude that a relationship between fNIRS\ndata and agent performance exists using classical machine learning techniques.\nFinally, we highlight the potential that neural interfaces may offer to future\napplications of human-agent interaction, assistive AI, and adaptive autonomous\nsystems.", "title_zh": "《从神经信号映射到智能体表现：迈向基于神经反馈的强化学习》", "AI": {"task": "将被动人类反馈整合到自主代理训练中的隐式人机循环强化学习（HITL-RL）方法", "motivation": "现有方法通常依赖主动指令，要求参与者通过不自然的表达或手势来教导代理", "method": "引入NEURO-LOOP框架，利用内在人类奖励系统驱动人机交互，并使用功能性近红外光谱（fNIRS）设计数据集", "result": "证明了fNIRS数据与代理性能之间存在关系，使用经典机器学习技术", "conclusion": "神经接口可能为未来的人机交互、辅助AI和自适应自主系统应用提供潜力"}}
{"id": "2506.12266v1", "pdf": "http://arxiv.org/pdf/2506.12266v1", "abs": "http://arxiv.org/abs/2506.12266v1", "authors": ["Avinash Baidya", "Kamalika Das", "Xiang Gao"], "title": "The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": "ACL 2025; 18 pages, 8 figures", "summary": "Large Language Model (LLM)-based agents have significantly impacted\nTask-Oriented Dialog Systems (TODS) but continue to face notable performance\nchallenges, especially in zero-shot scenarios. While prior work has noted this\nperformance gap, the behavioral factors driving the performance gap remain\nunder-explored. This study proposes a comprehensive evaluation framework to\nquantify the behavior gap between AI agents and human experts, focusing on\ndiscrepancies in dialog acts, tool usage, and knowledge utilization. Our\nfindings reveal that this behavior gap is a critical factor negatively\nimpacting the performance of LLM agents. Notably, as task complexity increases,\nthe behavior gap widens (correlation: 0.963), leading to a degradation of agent\nperformance on complex task-oriented dialogs. For the most complex task in our\nstudy, even the GPT-4o-based agent exhibits low alignment with human behavior,\nwith low F1 scores for dialog acts (0.464), excessive and often misaligned tool\nusage with a F1 score of 0.139, and ineffective usage of external knowledge.\nReducing such behavior gaps leads to significant performance improvement (24.3%\non average). This study highlights the importance of comprehensive behavioral\nevaluations and improved alignment strategies to enhance the effectiveness of\nLLM-based TODS in handling complex tasks.", "title_zh": "行为差距：面向复杂任务对话的零样本大语言模型智能体评估", "AI": {"task": "量化AI代理与人类专家在任务导向对话系统中的行为差距", "motivation": "基于大型语言模型(LLM)的代理在零样本场景下面临显著的性能挑战，行为因素对性能差距的影响尚未充分探索", "method": "提出一个全面的评估框架，专注于对话行为、工具使用和知识利用的差异", "result": "行为差距是影响LLM代理性能的关键因素，任务复杂性增加时行为差距扩大（相关性：0.963），减少行为差距可显著提高性能（平均24.3%）", "conclusion": "全面的行为评估和改进的对齐策略对于提升基于LLM的任务导向对话系统处理复杂任务的有效性至关重要"}}
{"id": "2506.11650v1", "pdf": "http://arxiv.org/pdf/2506.11650v1", "abs": "http://arxiv.org/abs/2506.11650v1", "authors": ["Lambert Lee", "Joshua Lau"], "title": "Robot Context Protocol (RCP): A Runtime-Agnostic Interface for Agent-Aware Robot Control", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "The Robot Context Protocol (RCP) is a lightweight, middleware-agnostic\ncommunication protocol designed to simplify the complexity of robotic systems\nand enable seamless interaction between robots, users, and autonomous agents.\nRCP provides a unified and semantically meaningful interface that decouples\nclient-facing operations from backend implementations, supporting a wide range\nof deployment environments including physical robots, cloud-based\norchestrators, and simulated platforms. Built on HTTP and WebSocket transport\nlayers, the protocol defines a schema-driven message format with structured\noperations such as read, write, execute, and subscribe. It integrates features\nsuch as runtime introspection, asynchronous feedback, multi-tenant namespace\nisolation, and strict type validation to ensure robustness, scalability, and\nsecurity. The architecture, message structure, interface model, and\nadapter-based backend integration strategy of RCP are described, along with\ndeployment practices and applicability across industries including\nmanufacturing, logistics, and healthcare. RCP enables intelligent, resilient,\nand safe robotic operations in complex, multi-agent ecosystems.", "title_zh": "机器人上下文协议（RCP）：一种运行时无关的智能体感知机器人控制接口", "AI": {"task": "设计Robot Context Protocol（RCP）以简化机器人系统的复杂性并实现机器人、用户和自主代理之间的无缝交互", "motivation": "为了支持包括物理机器人、基于云的协调器和模拟平台在内的广泛部署环境，需要一个统一且语义上有意义的接口来解耦面向客户的操作与后端实现", "method": "基于HTTP和WebSocket传输层，定义了一个模式驱动的消息格式，包括读取、写入、执行和订阅等结构化操作，并集成了运行时自省、异步反馈、多租户命名空间隔离和严格的类型验证等功能", "result": "描述了RCP的架构、消息结构、接口模型和基于适配器的后端集成策略，以及部署实践和在制造业、物流和医疗保健等行业的适用性", "conclusion": "RCP能够在复杂的多代理生态系统中实现智能、弹性和安全的机器人操作"}}
{"id": "2506.11475v1", "pdf": "http://arxiv.org/pdf/2506.11475v1", "abs": "http://arxiv.org/abs/2506.11475v1", "authors": ["Syeda Kisaa Fatima", "Tehreem Zubair", "Noman Ahmed", "Asifullah Khan"], "title": "AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction", "categories": ["cs.MA", "cs.CL", "cs.CV"], "comment": null, "summary": "This paper introduces LUCID-MA (Learning and Understanding Crime through\nDialogue of Multiple Agents), an innovative AI powered framework where multiple\nAI agents collaboratively analyze and understand crime data. Our system that\nconsists of three core components: an analysis assistant that highlights\nspatiotemporal crime patterns, a feedback component that reviews and refines\nanalytical results and a prediction component that forecasts future crime\ntrends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it\nruns completely offline and allows the agents undergo self-improvement through\n100 rounds of communication with less human interaction. A scoring function is\nincorporated to evaluate agent's performance, providing visual plots to track\nlearning progress. This work demonstrates the potential of AutoGen-style agents\nfor autonomous, scalable, and iterative analysis in social science domains\nmaintaining data privacy through offline execution.", "title_zh": "基于AutoGen驱动的多智能体框架在犯罪数据迭代分析与预测中的应用", "AI": {"task": "介绍LUCID-MA框架，一个创新的AI驱动框架，通过多代理对话学习和理解犯罪数据", "motivation": "为了通过多AI代理协作分析和理解犯罪数据，减少人工干预，同时保持数据隐私", "method": "系统包含三个核心组件：分析助手、反馈组件和预测组件，使用LLaMA-2-13B-Chat-GPTQ模型和精心设计的提示，完全离线运行，并通过100轮通信实现自我改进", "result": "通过评分函数评估代理性能，提供视觉图跟踪学习进度，展示了AutoGen风格代理在社会科学领域进行自主、可扩展和迭代分析的潜力", "conclusion": "LUCID-MA框架展示了通过离线执行保持数据隐私的同时，利用多AI代理协作进行犯罪数据分析和预测的潜力"}}
{"id": "2506.09755v1", "pdf": "http://arxiv.org/pdf/2506.09755v1", "abs": "http://arxiv.org/abs/2506.09755v1", "authors": ["Shuo Jiang", "Min Xie", "Frank Youhua Chen", "Jian Ma", "Jianxi Luo"], "title": "Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era", "categories": ["cs.CE", "cs.AI", "I.2.7; I.2.1"], "comment": null, "summary": "Research and practice in Intelligent Design (ID) have significantly enhanced\nengineering innovation, efficiency, quality, and productivity over recent\ndecades, fundamentally reshaping how engineering designers think, behave, and\ninteract with design processes. The recent emergence of Foundation Models\n(FMs), particularly Large Language Models (LLMs), has demonstrated general\nknowledge-based reasoning capabilities, and open new paths and avenues for\nfurther transformation in engineering design. In this context, this paper\nintroduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by\nagentic AI systems. We review the historical evolution of ID across four\ndistinct stages: rule-based expert systems, task-specific machine learning\nmodels, large-scale foundation AI models, and the recent emerging paradigm of\nmulti-agent collaboration. We propose a conceptual framework for ID 4.0 and\ndiscuss its potential to support end-to-end automation of engineering design\nprocesses through coordinated, autonomous multi-agent-based systems.\nFurthermore, we discuss future perspectives to enhance and fully realize ID\n4.0's potential, including more complex design scenarios, more practical design\nimplementations, novel agent coordination mechanisms, and autonomous design\ngoal-setting with better human value alignment. In sum, these insights lay a\nfoundation for advancing Intelligent Design toward greater adaptivity,\nautonomy, and effectiveness in addressing increasingly complex design\nchallenges.", "title_zh": "智能设计4.0：迈向智能体AI时代的范式演进", "AI": {"task": "介绍智能设计4.0（ID 4.0）作为一个由代理性AI系统赋能的新兴范式", "motivation": "基础模型（FMs），特别是大型语言模型（LLMs）的出现，展示了基于知识的通用推理能力，为工程设计的进一步转型开辟了新路径", "method": "回顾智能设计的历史演变，提出ID 4.0的概念框架，并讨论其通过协调、自主的多代理系统支持工程设计过程端到端自动化的潜力", "result": "提出了ID 4.0的概念框架，并讨论了其在支持工程设计过程端到端自动化方面的潜力", "conclusion": "这些见解为推进智能设计朝着更大的适应性、自主性和有效性方向发展，以应对日益复杂的设计挑战奠定了基础"}}
{"id": "2506.09420v1", "pdf": "http://arxiv.org/pdf/2506.09420v1", "abs": "http://arxiv.org/abs/2506.09420v1", "authors": ["Henry Peng Zou", "Wei-Chieh Huang", "Yaozu Wu", "Chunyu Miao", "Dongyuan Li", "Aiwei Liu", "Yue Zhou", "Yankai Chen", "Weizhi Zhang", "Yangning Li", "Liancheng Fang", "Renhe Jiang", "Philip S. Yu"], "title": "A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.LG", "cs.MA"], "comment": null, "summary": "Recent improvements in large language models (LLMs) have led many researchers\nto focus on building fully autonomous AI agents. This position paper questions\nwhether this approach is the right path forward, as these autonomous systems\nstill have problems with reliability, transparency, and understanding the\nactual requirements of human. We suggest a different approach: LLM-based\nHuman-Agent Systems (LLM-HAS), where AI works with humans rather than replacing\nthem. By keeping human involved to provide guidance, answer questions, and\nmaintain control, these systems can be more trustworthy and adaptable. Looking\nat examples from healthcare, finance, and software development, we show how\nhuman-AI teamwork can handle complex tasks better than AI working alone. We\nalso discuss the challenges of building these collaborative systems and offer\npractical solutions. This paper argues that progress in AI should not be\nmeasured by how independent systems become, but by how well they can work with\nhumans. The most promising future for AI is not in systems that take over human\nroles, but in those that enhance human capabilities through meaningful\npartnership.", "title_zh": "《协同智能的呼唤：为何人机协作系统应优先于人工智能自主性》", "AI": {"task": "探讨大型语言模型（LLMs）是否应该追求完全自主的AI代理，以及提出LLM-based Human-Agent Systems（LLM-HAS）作为替代方案", "motivation": "完全自主的AI系统在可靠性、透明度和理解人类实际需求方面仍存在问题", "method": "提出LLM-HAS方法，通过保持人类的参与来提供指导、回答问题和维持控制，使系统更可信和适应性强", "result": "通过医疗、金融和软件开发等领域的例子展示了人-AI团队合作比AI单独工作更能有效处理复杂任务，并讨论了构建这些协作系统的挑战及实用解决方案", "conclusion": "AI的进步不应以系统的独立性来衡量，而应以它们与人类合作的能力来衡量；AI最有前途的未来不在于接管人类角色的系统，而在于通过有意义的伙伴关系增强人类能力的系统"}}
